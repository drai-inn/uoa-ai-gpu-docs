{"config":{"separator":"[\\s\\-_,:!=\\[\\]()\\\\\"`/]+|\\.(?!\\d)"},"items":[{"location":"","level":1,"title":"Index","text":"Research AI GPU Platform Accelerating research with high-performance computing, scalable infrastructure, and secure management. Get Started View Architecture <ul> <li> <p> Scalable Infrastructure</p> <p>Built on Kubernetes to provide flexible and scalable GPU resources for diverse research workloads, from training to inference.</p> </li> <li> <p> Secure &amp; Managed</p> <p>Integrated with Keycloak for secure authentication and robust policy management, ensuring your research data remains protected.</p> </li> <li> <p> Research Focused</p> <p>Tailored specifically to support the needs of academic research, providing the compute power required for breakthrough discoveries.</p> </li> <li> <p> Community Driven</p> <p>Built by researchers, for researchers. Contribute your own guides, fix issues, and help shape the platform.</p> </li> </ul>","path":["Index"],"tags":[]},{"location":"#quick-links","level":2,"title":"Quick Links","text":"<ul> <li> <p>Accessing the Cluster     ---     Guide on how to authenticate and connect to the Kubernetes cluster.</p> </li> <li> <p>Running LLMs on NeSI     ---     Step-by-step guide to deploying Large Language Models.</p> </li> <li> <p>Platform Overview     ---     Deep dive into the cluster architecture and components.</p> </li> <li> <p>Benchmarks     ---     Performance metrics and comparison data.</p> </li> </ul>","path":["Index"],"tags":[]},{"location":"guides/","level":1,"title":"Guides","text":"<ul> <li>Accessing the Cluster</li> <li>LLM on NeSI</li> </ul>","path":["Guides"],"tags":[]},{"location":"guides/accessing-the-cluster/","level":1,"title":"Accessing the Kubernetes Cluster","text":"","path":["Guides","Accessing the Kubernetes Cluster"],"tags":[]},{"location":"guides/accessing-the-cluster/#1-prerequisites","level":2,"title":"1. Prerequisites","text":"<p>Ensure you have <code>kubectl</code> installed.</p> <pre><code>sudo apt-get update\nsudo apt-get install -y kubectl\n</code></pre> <p>This configuration uses OIDC (OpenID Connect) for authentication via Keycloak. To access the cluster, you must have the <code>oidc-login</code> plugin installed.</p> <p>If you have Krew installed, this is the most reliable method: <pre><code>kubectl krew install oidc-login\n</code></pre></p>","path":["Guides","Accessing the Kubernetes Cluster"],"tags":[]},{"location":"guides/accessing-the-cluster/#2-set-up-the-config-file","level":2,"title":"2. Set up the config file","text":"<p>Below YAML is the configuration file that you need to connect to the cluster. By default, Kubectl will look for this file in <code>~/.kube/config</code>.</p> <pre><code>apiVersion: v1\nclusters:\n- cluster:\n    certificate-authority-data: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSUM2akNDQWRLZ0F3SUJBZ0lCQURBTkJna3Foa2lHOXcwQkFRc0ZBREFWTVJNd0VRWURWUVFERXdwcmRXSmwKY201bGRHVnpNQjRYRFRJMU1UQXdOakl4TkRFeE1Gb1hEVE0xTVRBd05ESXhORFl4TUZvd0ZURVRNQkVHQTFVRQpBeE1LYTNWaVpYSnVaWFJsY3pDQ0FTSXdEUVlKS29aSWh2Y05BUUVCQlFBRGdnRVBBRENDQVFvQ2dnRUJBTFdDCnFsMXl6b1RGOGVuSFMwalA1SXFtN3JhYWtaZzMvcFJpd0hjTWFPTDZBQUFkdGpEMWNMRkVpQ1EwRzdpN1lIVEwKMmxTd0FNanUvYXN5WXRNMWV5Nzc1K2J2UzM2V2Z4ajlmUTZ6NXBDR0I5eExqRzVnSG5rWURYRGFrVlI2bGl1ZApQM0lpemthOXFPTzBVdmpEVGh2TDRPd3Z0dUtKV0VFM0RYcXpMcmJvVmF4RmdROFY3ZmVnWDJUcXJBWEZ5SS83Cnk4RlliTWJMRUJvdHh3V3RnTXlGMlllQ09pT2VOTCt4cnAyQjZ5aGV5ZG8zQmJzRkNPY3RhQTFIV1dqQ3BHc0kKWWUvcFVYRlVNU29DMkpMM2toK3k3UTFia1ZpUm9jaHBEY3VaQUxpbUUxaTBZdEdST0d0bW9QdDdEaFBkNnJNcwpxeUNsemFCdk53NFJmRmo3UzY4Q0F3RUFBYU5GTUVNd0RnWURWUjBQQVFIL0JBUURBZ0trTUJJR0ExVWRFd0VCCi93UUlNQVlCQWY4Q0FRQXdIUVlEVlIwT0JCWUVGTEI4TEVuWTRJZFpMdExkY3lkNjNiQlcwalVNTUEwR0NTcUcKU0liM0RRRUJDd1VBQTRJQkFRQTRwSFQ1ZnV1aUZTTkJhUmlLRFpyRE5Nc0tNbmdUTGhJTHdpT3pXQk11NGd3MgpRQ3c3N0xWcTBHbWhENG5iQmUvNjI3dkhjeEVKV1NBd25jYUZvQ09zNzFIVkhBUnBMRks5SXN6VkdVZjlYOG1vCkdJeTVMbnBvcGRlU0NUa3hjSk5oUU1QNURlMjhvYThlUEU0K0prRFM5Q3dPWTVVSDBPY204RElKalphWjhYUy8KZmxYNXFJNHgvOXRtZnQ0M3d4Vk4zS25VMVJtSjhSUzFNSFZkNDdwWE5ZUTBqY2hrNEtyYkM1T2t6T1dBMktFNwpPZXBPTS9VUGlsVG1DR1owMENNNGFWVW8yMCsxQUU2aVRIWVdnNndxUHhwVHBxRGorUko1bXJzb2QrcWJ2NUR3CncxQlNyNVRXbFRMbVRCMlZSc0JUWFc2Ri8rSXFGUFdtQTRrcno2UHoKLS0tLS1FTkQgQ0VSVElGSUNBVEUtLS0tLQo=\n    server: https://163.7.145.113:6443\n  name: capi131-drai-ai-test\ncontexts:\n- context:\n    cluster: capi131-drai-ai-test\n    user: oidc\n  name: capi131-drai-ai-test\ncurrent-context: capi131-drai-ai-test\nkind: Config\npreferences: {}\nusers:\n- name: oidc\n  user:\n    exec:\n      apiVersion: client.authentication.k8s.io/v1\n      args:\n      - oidc-login\n      - get-token\n      - --oidc-issuer-url=https://keycloak.test.drai.auckland.ac.nz/realms/drai\n      - --oidc-client-id=k8s-test\n      - --oidc-client-secret=0JgSbpmVgvqNpjxn5u5ExcMeLpGCcRYi\n      - --oidc-extra-scope=groups\n      command: kubectl\n      env: null\n      interactiveMode: Never\n      provideClusterInfo: false\n</code></pre>","path":["Guides","Accessing the Kubernetes Cluster"],"tags":[]},{"location":"guides/accessing-the-cluster/#3-connecting-to-the-cluster","level":2,"title":"3. Connecting to the Cluster","text":"<p>Upon running your first <code>kubectl</code> command:</p> <ol> <li>A browser window will automatically open loading the Keycloak login page.</li> <li>Log in with your standard credentials.</li> <li>Once authenticated, the browser will display \"You are logged in,\" and your terminal command will execute.</li> </ol> <p>Here are some useful commands to get started:</p> <pre><code>kubectl get pods -n kai-test\nkubectl get services -n kai-test\n</code></pre>","path":["Guides","Accessing the Kubernetes Cluster"],"tags":[]},{"location":"guides/accessing-the-cluster/#caveats","level":2,"title":"Caveats","text":"<p>At this stage, we are still working on the Tuakiri integration, and only able to provide you access if you already have an account with us. Please reach out to jun.huh@auckland.ac.nz if you would like to request an account.</p>","path":["Guides","Accessing the Kubernetes Cluster"],"tags":[]},{"location":"guides/llm-on-nesi/","level":1,"title":"Running LLMs on NeSI","text":"<p>This guide provides an overview of how to deploy and run Large Language Models (LLMs) on the NeSI HPC platform using the UoA AI GPU resources.</p>","path":["Guides","Running LLMs on NeSI"],"tags":[]},{"location":"guides/llm-on-nesi/#prerequisites","level":2,"title":"Prerequisites","text":"<p>Before you begin, ensure you have:</p> <ul> <li>Docker Engine: Installed locally (e.g., Docker Desktop).</li> <li>SSH Access: Configured SSH keys for accessing the VM (<code>GatewayPorts yes</code> required in <code>sshd_config</code>).</li> <li>DuckDNS: A domain and API key for external access.</li> <li>API Keys: OpenAI, LiteLLM, etc., as needed for your specific model.</li> </ul>","path":["Guides","Running LLMs on NeSI"],"tags":[]},{"location":"guides/llm-on-nesi/#quick-start","level":2,"title":"Quick Start","text":"<ol> <li>Configuration: Create a <code>.env</code> file with your secrets (API keys, passwords).</li> <li>Launch: Run <code>sudo docker compose up -d</code> to start the services.</li> <li>HPC Job Submission: Use the provided Slurm scripts to submit your model inference job to the HPC nodes.</li> </ol>","path":["Guides","Running LLMs on NeSI"],"tags":[]},{"location":"guides/llm-on-nesi/#repository","level":2,"title":"Repository","text":"<p>For the full tutorial, example <code>.env</code> files, and Slurm submission scripts, please refer to the source repository:</p> <p>drai-inn/llm-nesi-example</p>","path":["Guides","Running LLMs on NeSI"],"tags":[]},{"location":"platform/","level":1,"title":"Platform","text":"<ul> <li>Overview</li> </ul>","path":["Platform"],"tags":[]},{"location":"platform/overview/","level":1,"title":"Platform Architecture","text":"<p>The UoA Research AI GPU Platform is designed to provide a scalable and secure environment for AI research.</p>","path":["Platform","Platform Architecture"],"tags":[]},{"location":"platform/overview/#overview","level":2,"title":"Overview","text":"<p>The platform is built as a Kubernetes (K8s) environment, integrating various components to manage user access, security, and resource allocation.</p>","path":["Platform","Platform Architecture"],"tags":[]},{"location":"platform/overview/#key-components","level":3,"title":"Key Components","text":"<ul> <li>Kubernetes Cluster: The core orchestration layer for managing containerized AI workloads.</li> <li>Keycloak: Handles user authentication and role-based access control (RBAC).</li> <li>Policies: Defines usage policies and resource limits for different user roles.</li> </ul>","path":["Platform","Platform Architecture"],"tags":[]},{"location":"platform/overview/#repository","level":2,"title":"Repository","text":"<p>For detailed configuration files, including K8s manifests, Keycloak setup, and policy definitions, please refer to the source repository:</p> <p>drai-inn/ai-gpu-platform</p>","path":["Platform","Platform Architecture"],"tags":[]},{"location":"reference/benchmarks/","level":1,"title":"AI Benchmarks","text":"<p>This section tracks performance benchmarks for various AI models and hardware configurations on the platform.</p>","path":["Reference","AI Benchmarks"],"tags":[]},{"location":"reference/benchmarks/#repository","level":2,"title":"Repository","text":"<p>We maintain a collection of benchmark scripts and results in the following repository:</p> <p>drai-inn/ai-benchmarks</p> <p>Note: Detailed benchmark results and methodologies will be populated here as they become available.</p>","path":["Reference","AI Benchmarks"],"tags":[]}]}